{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1. Content image, C => image to put style on\n",
    "####  2. Style image, S\n",
    "####  3. Generated image, G => Content image with style of S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pretrained model, going to take activation of hidden layer somewhere in the middle of the network as result. And Using custom Cost function going to tune the network, to create a C image with style of S, image G **Using aG activation of dimension (1, nH, nW, nC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Defining Cost for the neural netwrok\n",
    "\n",
    "1. Content cost, JC\n",
    "2. Style cost, SC\n",
    "3. Combining the two costs, J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Content Cost, JC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content cost takes a hidden layer activation for both C and G images, aC and aG, and measure their difference. So, when we minimize this cost, it will make Genrated image G contents similar to C image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contentCost(aC, aG):\n",
    "    \"\"\"\n",
    "    Computes the content cost\n",
    "    \n",
    "    Arguments:\n",
    "    aC -- tensor of dimension (1, nH, nW, nC)\n",
    "    aG -- tensor of dimension (1, nH, nW, nC)\n",
    "    \n",
    "    Returns: \n",
    "    JC -- cost for the content image\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve dimensions from a_G\n",
    "    m, nH, nW, nC = aG.get_shape().as_list()\n",
    "    \n",
    "    # Reshape aC and aG\n",
    "    aC_unrolled = tf.reshape(aC, [m, nH * nW, nC])\n",
    "    aG_unrolled = tf.reshape(aG, [m, nH * nW, nC])\n",
    "    \n",
    "    \n",
    "    JC = (1 / (4 * nH * nW * nC)) * tf.reduce_sum(tf.square(tf.subtract(aC_unrolled, aG_unrolled)))\n",
    "        \n",
    "    return JC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Style Cost, JS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gram matrix G of a set of vectors (v1,…,vn) is the matrix of dot products\n",
    "\n",
    "Gij = np.dot(vi,vj)\n",
    "\n",
    "large Gij means vi is very similar to vj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gramMatrix(A):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    A -- matrix of shape (nC, nH * nW)\n",
    "    \n",
    "    Returns:\n",
    "    GM -- Gram matrix of A, of shape (nC, nC)\n",
    "    \"\"\"\n",
    "    \n",
    "    GM = tf.matmul(A, A, transpose_b=True)\n",
    "    \n",
    "    return GM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to minimize the distance between the Gram matrix of the style image S and that of the generated image G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def styleCost(aS, aG):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    aS -- tensor of dimension (1, nH, nW, nC)\n",
    "    aG -- tensor of dimension (1, nH, nW, nC)\n",
    "    \n",
    "    Returns: \n",
    "    JS -- scalar style cost\n",
    "    \"\"\"\n",
    "    \n",
    "    m, nH, nW, nC = aG.get_shape().as_list()\n",
    "    \n",
    "    # Reshape the images\n",
    "    # if m images, need to use a for loop\n",
    "    aS = tf.transpose(tf.reshape(aS, [nH * nW, nC]))\n",
    "    aG = tf.transpose(tf.reshape(aG, [nH * nW, nC]))\n",
    "\n",
    "    # Computing gram_matrices for S and G\n",
    "    GMS = gramMatrix(aS)\n",
    "    GMG = gramMatrix(aG)\n",
    "    \n",
    "    \n",
    "    # Computing the loss (≈1 line)\n",
    "    JS = (1 / ((2 * nC * nH * nW) ** 2)) * tf.reduce_sum(tf.square(tf.subtract(GMS, GMG)))\n",
    "        \n",
    "    return JS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can get better results if use style cost from different layers and combine them using weighted average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "layerWeights = [('conv1_1', 0.2),\n",
    "                ('conv2_1', 0.2),\n",
    "                ('conv3_1', 0.2),\n",
    "                ('conv4_1', 0.2),\n",
    "                ('conv5_1', 0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightedStyleCost(model, layerWeights):\n",
    "    \"\"\"\n",
    "    Computes the overall style cost from several chosen layers\n",
    "    \n",
    "    Arguments:\n",
    "    model -- tensorflow model\n",
    "    layerWeights -- layers to extract style from with correspinding weights to use\n",
    "    \n",
    "    Returns: \n",
    "    JS -- weighted style cost\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize the overall style cost\n",
    "    JS = 0\n",
    "\n",
    "    for layer, w in layerWeights:\n",
    "\n",
    "        # output tensor of the current layer\n",
    "        out = model[layer]\n",
    "\n",
    "        # Set aS to be the hidden layer activation by running the session on out\n",
    "        aS = sess.run(out)\n",
    "\n",
    "        # Set aG to be the hidden layer activation from the same layer,\n",
    "        # going to execute later when we set input as G and run the session\n",
    "        aG = out\n",
    "        \n",
    "        # Compute style_cost for the current layer\n",
    "        JSlayer = styleCost(aS, aG)\n",
    "\n",
    "        # Add weighted average to overall style cost\n",
    "        JS += w * JSlayer\n",
    "\n",
    "    return JS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimizing the weighted style cost will cause the image G to follow the style of the image S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Total Cost, J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weighted average of the content cost and the style cost, using alpha and beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def totalCost(JC, JS, alpha = 10, beta = 40):\n",
    "    \"\"\"\n",
    "    Computes the total cost\n",
    "    \n",
    "    Arguments:\n",
    "    JC -- content cost\n",
    "    JS -- weighted style cost\n",
    "    alpha -- hyperparameter weighting the importance of the content cost\n",
    "    beta -- hyperparameter weighting the importance of the style cost\n",
    "    \n",
    "    Returns:\n",
    "    J -- total cost\n",
    "    \"\"\"\n",
    "    \n",
    "    return (alpha * JC) + (beta * JS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create an Interactive session\n",
    "2. load content image\n",
    "3. load style image\n",
    "4. add random noise to the content image, to create initial generated image\n",
    "5. load pretrained model\n",
    "6. build the tensorflow graph\n",
    "   1. Run the content image through the model and compute the content cost\n",
    "   2. Run the style image through the model and compute the style cost\n",
    "   3. Compute the total cost\n",
    "   4. Define the optimizer and the learning rate\n",
    "7. initialize the tensorflow graph and run it for no. of iterations while updating genrated image G at every step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create an Interactive session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Start interactive session\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. load content image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load content image\n",
    "C = scipy.misc.imread(\"images/louvre_small.jpg\")\n",
    "\n",
    "# preprocess the image\n",
    "C = reshape_and_normalize_image(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. load style image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the style image\n",
    "S = scipy.misc.imread(\"images/monet.jpg\")\n",
    "\n",
    "# preprocess the image\n",
    "S = reshape_and_normalize_image(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. add random noise to the content image, to create initial generated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate noisy version of the content image\n",
    "G = generate_noise_image(C)\n",
    "imshow(G[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pretrained model\n",
    "model = load_vgg_model(\"pretrained-model/imagenet-vgg-verydeep-19.mat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. build the tensorflow graph\n",
    "   1. Run the content image through the model and compute the content cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the content image to be the input of the model\n",
    "sess.run(model['input'].assign(C))\n",
    "\n",
    "# Select the output tensor of layer conv4_2\n",
    "out = model['conv4_2']\n",
    "\n",
    "# Set aC to be the hidden layer activation\n",
    "aC = sess.run(out)\n",
    "\n",
    "# Set aG to be the hidden layer activation from the same layer,\n",
    "# going to execute later when we set input as G and run the session\n",
    "aG = out\n",
    "\n",
    "# Compute the content cost\n",
    "JC = contentCost(aC, aG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1. Content image, C => image to put style on\n",
    "####  2. Style image, S\n",
    "####  3. Generated image, G => Content image with style of S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pretrained model, going to take activation of hidden layer somewhere in the middle of the network as result. And Using custom Cost function going to tune the network, to create a C image with style of S, image G **Using aG activation of dimension (1, nH, nW, nC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Defining Cost for the neural netwrok\n",
    "\n",
    "1. Content cost, JC\n",
    "2. Style cost, SC\n",
    "3. Combining the two costs, J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Content Cost, JC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content cost takes a hidden layer activation for both C and G images, aC and aG, and measure their difference. So, when we minimize this cost, it will make Genrated image G contents similar to C image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contentCost(aC, aG):\n",
    "    \"\"\"\n",
    "    Computes the content cost\n",
    "    \n",
    "    Arguments:\n",
    "    aC -- tensor of dimension (1, nH, nW, nC)\n",
    "    aG -- tensor of dimension (1, nH, nW, nC)\n",
    "    \n",
    "    Returns: \n",
    "    JC -- cost for the content image\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve dimensions from a_G\n",
    "    m, nH, nW, nC = aG.get_shape().as_list()\n",
    "    \n",
    "    # Reshape aC and aG\n",
    "    aC_unrolled = tf.reshape(aC, [m, nH * nW, nC])\n",
    "    aG_unrolled = tf.reshape(aG, [m, nH * nW, nC])\n",
    "    \n",
    "    \n",
    "    JC = (1 / (4 * nH * nW * nC)) * tf.reduce_sum(tf.square(tf.subtract(aC_unrolled, aG_unrolled)))\n",
    "        \n",
    "    return JC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Style Cost, JS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gram matrix G of a set of vectors (v1,…,vn) is the matrix of dot products\n",
    "\n",
    "Gij = np.dot(vi,vj)\n",
    "\n",
    "large Gij means vi is very similar to vj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gramMatrix(A):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    A -- matrix of shape (nC, nH * nW)\n",
    "    \n",
    "    Returns:\n",
    "    GM -- Gram matrix of A, of shape (nC, nC)\n",
    "    \"\"\"\n",
    "    \n",
    "    GM = tf.matmul(A, A, transpose_b=True)\n",
    "    \n",
    "    return GM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to minimize the distance between the Gram matrix of the style image S and that of the generated image G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def styleCost(aS, aG):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    aS -- tensor of dimension (1, nH, nW, nC)\n",
    "    aG -- tensor of dimension (1, nH, nW, nC)\n",
    "    \n",
    "    Returns: \n",
    "    JS -- scalar style cost\n",
    "    \"\"\"\n",
    "    \n",
    "    m, nH, nW, nC = aG.get_shape().as_list()\n",
    "    \n",
    "    # Reshape the images\n",
    "    # if m images, need to use a for loop\n",
    "    aS = tf.transpose(tf.reshape(aS, [nH * nW, nC]))\n",
    "    aG = tf.transpose(tf.reshape(aG, [nH * nW, nC]))\n",
    "\n",
    "    # Computing gram_matrices for S and G\n",
    "    GMS = gramMatrix(aS)\n",
    "    GMG = gramMatrix(aG)\n",
    "    \n",
    "    \n",
    "    # Computing the loss (≈1 line)\n",
    "    JS = (1 / ((2 * nC * nH * nW) ** 2)) * tf.reduce_sum(tf.square(tf.subtract(GMS, GMG)))\n",
    "        \n",
    "    return JS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can get better results if use style cost from different layers and combine them using weighted average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "layerWeights = [('conv1_1', 0.2),\n",
    "                ('conv2_1', 0.2),\n",
    "                ('conv3_1', 0.2),\n",
    "                ('conv4_1', 0.2),\n",
    "                ('conv5_1', 0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightedStyleCost(model, layerWeights):\n",
    "    \"\"\"\n",
    "    Computes the overall style cost from several chosen layers\n",
    "    \n",
    "    Arguments:\n",
    "    model -- tensorflow model\n",
    "    layerWeights -- layers to extract style from with correspinding weights to use\n",
    "    \n",
    "    Returns: \n",
    "    JS -- weighted style cost\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize the overall style cost\n",
    "    JS = 0\n",
    "\n",
    "    for layer, w in layerWeights:\n",
    "\n",
    "        # output tensor of the current layer\n",
    "        out = model[layer]\n",
    "\n",
    "        # Set aS to be the hidden layer activation by running the session on out\n",
    "        aS = sess.run(out)\n",
    "\n",
    "        # Set aG to be the hidden layer activation from the same layer,\n",
    "        # going to execute later when we set input as G and run the session\n",
    "        aG = out\n",
    "        \n",
    "        # Compute style_cost for the current layer\n",
    "        JSlayer = styleCost(aS, aG)\n",
    "\n",
    "        # Add weighted average to overall style cost\n",
    "        JS += w * JSlayer\n",
    "\n",
    "    return JS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimizing the weighted style cost will cause the image G to follow the style of the image S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Total Cost, J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_cost(JC, JS, alpha = 10, beta = 40):\n",
    "    \"\"\"\n",
    "    Computes the total cost\n",
    "    \n",
    "    Arguments:\n",
    "    JC -- content cost\n",
    "    JS -- weighted style cost\n",
    "    alpha -- hyperparameter weighting the importance of the content cost\n",
    "    beta -- hyperparameter weighting the importance of the style cost\n",
    "    \n",
    "    Returns:\n",
    "    J -- total cost\n",
    "    \"\"\"\n",
    "    \n",
    "    return (alpha * JC) + (beta * JS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
